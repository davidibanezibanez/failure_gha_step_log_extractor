{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12c6c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando repositorio: davidibanezibanez/example-failing-workflows\n",
      "Encontrados 4 workflow runs fallidos\n",
      "Procesando workflow run: Fail Workflow 1 (ID: 15814985792)\n",
      "  Analizando job fallido: intentional-fail-job-1\n",
      "    Guardado log de failure: github_failure_logs\\davidibanezibanez_example-failing-workflows_Fail Workflow 1_intentional-fail-job-1_2025-06-23T0406595385363Z Run exit 1_20250623_000752.txt\n",
      "Procesando workflow run: Fail Workflow 4 (ID: 15814985795)\n",
      "  Analizando job fallido: intentional-fail-job-4\n",
      "    Guardado log de failure: github_failure_logs\\davidibanezibanez_example-failing-workflows_Fail Workflow 4_intentional-fail-job-4_2025-06-23T0406594452798Z Run echo This is Job 1_20250623_000754.txt\n",
      "  Analizando job fallido: intentional-fail-job-4_1\n",
      "    Guardado log de failure: github_failure_logs\\davidibanezibanez_example-failing-workflows_Fail Workflow 4_intentional-fail-job-4_1_2025-06-23T0406595170977Z Run echo This is Job 2_20250623_000755.txt\n",
      "Procesando workflow run: Fail Workflow 3 (ID: 15814985796)\n",
      "  Analizando job fallido: intentional-fail-job-3\n",
      "    Guardado log de failure: github_failure_logs\\davidibanezibanez_example-failing-workflows_Fail Workflow 3_intentional-fail-job-3_2025-06-23T0407004137320Z Run exit 1_20250623_000757.txt\n",
      "Procesando workflow run: Fail Workflow 2 (ID: 15814985801)\n",
      "  Analizando job fallido: intentional-fail-job-2\n",
      "    Guardado log de failure: github_failure_logs\\davidibanezibanez_example-failing-workflows_Fail Workflow 2_intentional-fail-job-2_2025-06-23T0407017653421Z Run echo Building_20250623_000759.txt\n",
      "\n",
      "Análisis completado. Se guardaron 5 logs de failures.\n"
     ]
    }
   ],
   "source": [
    "# Failure GHA step log extractor\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Configuración\n",
    "load_dotenv()\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN')  # Token de Github\n",
    "OWNER = \"davidibanezibanez\"  # Owner del repositorio\n",
    "REPO = \"example-failing-workflows\"  # Nombre del repositorio\n",
    "\n",
    "def sanitize_filename(name, max_length=100):\n",
    "    # Solo permite letras, números, guiones, guiones bajos y espacios\n",
    "        name = re.sub(r'[^a-zA-Z0-9 \\-_]', '', name)\n",
    "        return name.strip()[:max_length]\n",
    "\n",
    "def extract_error_lines(logs):\n",
    "    error_lines = []\n",
    "    for line in logs.split('\\n'):\n",
    "        if '##[error]' in line or 'Error:' in line or 'error:' in line:\n",
    "            error_lines.append(line)\n",
    "    return '\\n'.join(error_lines) if error_lines else '[No se detectó un mensaje de error explícito]'\n",
    "\n",
    "class GitHubWorkflowLogger:\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "        self.headers = {\n",
    "            'Authorization': f'token {token}',\n",
    "            'Accept': 'application/vnd.github.v3+json'\n",
    "        }\n",
    "        self.base_url = 'https://api.github.com'\n",
    "    \n",
    "    def get_workflow_runs(self, owner, repo, per_page=10):\n",
    "        \"\"\"Obtiene los workflow runs con status failure de un repositorio\"\"\"\n",
    "        url = f\"{self.base_url}/repos/{owner}/{repo}/actions/runs\"\n",
    "        params = {\n",
    "            'status': 'failure',\n",
    "            'per_page': per_page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['workflow_runs']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error obteniendo workflow runs: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_jobs_for_run(self, owner, repo, run_id):\n",
    "        \"\"\"Obtiene los jobs de un workflow run específico\"\"\"\n",
    "        url = f\"{self.base_url}/repos/{owner}/{repo}/actions/runs/{run_id}/jobs\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return response.json()['jobs']\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error obteniendo jobs para run {run_id}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def get_job_logs(self, owner, repo, job_id):\n",
    "        \"\"\"Obtiene los logs de un job específico\"\"\"\n",
    "        url = f\"{self.base_url}/repos/{owner}/{repo}/actions/jobs/{job_id}/logs\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return response.text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error obteniendo logs para job {job_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def find_failed_steps_in_logs(self, logs):\n",
    "        \"\"\"Identifica los steps que fallaron en los logs\"\"\"\n",
    "        failed_steps = []\n",
    "        lines = logs.split('\\n')\n",
    "        current_step = None\n",
    "        step_logs = []\n",
    "        \n",
    "        for line in lines:\n",
    "            # Detectar inicio de step\n",
    "            if '##[group]' in line and 'Run ' in line:\n",
    "                if current_step and step_logs:\n",
    "                    # Verificar si el step anterior falló\n",
    "                    if any('##[error]' in log_line or 'Error:' in log_line for log_line in step_logs):\n",
    "                        failed_steps.append({\n",
    "                            'step_name': current_step,\n",
    "                            'logs': '\\n'.join(step_logs)\n",
    "                        })\n",
    "                \n",
    "                current_step = line.replace('##[group]', '').strip()\n",
    "                step_logs = []\n",
    "            \n",
    "            step_logs.append(line)\n",
    "        \n",
    "        # Verificar el último step\n",
    "        if current_step and step_logs:\n",
    "            if any('##[error]' in log_line or 'Error:' in log_line for log_line in step_logs):\n",
    "                failed_steps.append({\n",
    "                    'step_name': current_step,\n",
    "                    'logs': '\\n'.join(step_logs)\n",
    "                })\n",
    "        \n",
    "        return failed_steps\n",
    "    \n",
    "    def create_output_directory(self):\n",
    "        \"\"\"Crea el directorio de salida si no existe\"\"\"\n",
    "        output_dir = 'github_failure_logs'\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        return output_dir\n",
    "    \n",
    "    def save_failure_log(self, owner, repo, workflow_name, job_name, step_info, run_id, job_id, output_dir):\n",
    "        \"\"\"Guarda el log de un failure en un archivo\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        safe_workflow_name = \"\".join(c for c in workflow_name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        safe_job_name = \"\".join(c for c in job_name if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "        safe_step_name = sanitize_filename(step_info['step_name'])\n",
    "        \n",
    "        filename = f\"{owner}_{repo}_{safe_workflow_name}_{safe_job_name}_{safe_step_name}_{timestamp}.txt\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"Github workflow failure log\\n\")\n",
    "            f.write(f\"Repositorio: {owner}/{repo}\\n\")\n",
    "            f.write(f\"Workflow: {workflow_name}\\n\")\n",
    "            f.write(f\"Job: {job_name}\\n\")\n",
    "            f.write(f\"Step que falló: {step_info['step_name']}\\n\")\n",
    "            f.write(f\"Run ID: {run_id}\\n\")\n",
    "            f.write(f\"Job ID: {job_id}\\n\")\n",
    "            f.write(f\"Fecha de análisis: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(\"Mensaje(s) de error detectado(s):\\n\")\n",
    "            f.write(extract_error_lines(step_info['logs']))\n",
    "        \n",
    "        return filepath\n",
    "    \n",
    "    def analyze_repository(self, owner, repo):\n",
    "        \"\"\"Analiza un repositorio específico en busca de workflow failures\"\"\"\n",
    "        print(f\"Analizando repositorio: {owner}/{repo}\")\n",
    "        \n",
    "        output_dir = self.create_output_directory()\n",
    "        failure_count = 0\n",
    "        \n",
    "        # Obtener workflow runs fallidos\n",
    "        workflow_runs = self.get_workflow_runs(owner, repo)\n",
    "        \n",
    "        if not workflow_runs:\n",
    "            print(f\"No se encontraron workflow runs fallidos en {owner}/{repo}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Encontrados {len(workflow_runs)} workflow runs fallidos\")\n",
    "        \n",
    "        for run in workflow_runs:\n",
    "            run_id = run['id']\n",
    "            workflow_name = run['name']\n",
    "            \n",
    "            print(f\"Procesando workflow run: {workflow_name} (ID: {run_id})\")\n",
    "            \n",
    "            # Obtener jobs del workflow run\n",
    "            jobs = self.get_jobs_for_run(owner, repo, run_id)\n",
    "            \n",
    "            for job in jobs:\n",
    "                if job['conclusion'] == 'failure':\n",
    "                    job_id = job['id']\n",
    "                    job_name = job['name']\n",
    "                    \n",
    "                    print(f\"  Analizando job fallido: {job_name}\")\n",
    "                    \n",
    "                    # Obtener logs del job\n",
    "                    logs = self.get_job_logs(owner, repo, job_id)\n",
    "                    \n",
    "                    if logs:\n",
    "                        # Encontrar steps que fallaron\n",
    "                        failed_steps = self.find_failed_steps_in_logs(logs)\n",
    "                        \n",
    "                        if failed_steps:\n",
    "                            for step_info in failed_steps:\n",
    "                                filepath = self.save_failure_log(\n",
    "                                    owner, repo, workflow_name, job_name, \n",
    "                                    step_info, run_id, job_id, output_dir\n",
    "                                )\n",
    "                                print(f\"    Guardado log de failure: {filepath}\")\n",
    "                                failure_count += 1\n",
    "                        else:\n",
    "                            # Si no se pueden identificar steps específicos, guardar todo el log del job\n",
    "                            step_info = {\n",
    "                                'step_name': 'Job_Complete_Log',\n",
    "                                'logs': logs\n",
    "                            }\n",
    "                            filepath = self.save_failure_log(\n",
    "                                owner, repo, workflow_name, job_name, \n",
    "                                step_info, run_id, job_id, output_dir\n",
    "                            )\n",
    "                            print(f\"    Guardado log completo del job: {filepath}\")\n",
    "                            failure_count += 1\n",
    "            \n",
    "            # Breve pausa para no sobrecargar la API\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(f\"\\nAnálisis completado. Se guardaron {failure_count} logs de failures.\")\n",
    "\n",
    "# Ejecución\n",
    "if not GITHUB_TOKEN:\n",
    "    print(\"ERROR: configurar token de GitHub en la variable GITHUB_TOKEN\")\n",
    "elif not OWNER or not REPO:\n",
    "    print(\"ERROR: configurar OWNER y REPO\")\n",
    "else:\n",
    "    # Crear instancia del logger\n",
    "    logger = GitHubWorkflowLogger(GITHUB_TOKEN)\n",
    "    \n",
    "    # Analizar repositorio\n",
    "    logger.analyze_repository(OWNER, REPO)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
